commit 8f04cffe25ca339841ce0ac67c98bb9a74caa9fc
Author: Alexey Serbin <alexey@apache.org>
Date:   Fri Oct 6 17:49:39 2023 -0700

    Substitute namespaces
    
    perl -p -i -e 's,base::,tcmalloc::,g' $(find . -name *.h -o -name \*.cc)
    perl -p -i -e 's,namespace base,namespace tcmalloc,g' $(find . -name *.h -o -name \*.cc)

diff --git a/src/base/basictypes.h b/src/base/basictypes.h
index a6b60ad..144a2e0 100644
--- a/src/base/basictypes.h
+++ b/src/base/basictypes.h
@@ -422,15 +422,15 @@ union MemoryAligner {
 // that the variable has static storage class, and that the constructor should
 // do nothing to its state.  It indicates to the reader that it is legal to
 // declare a static nistance of the class, provided the constructor is given
-// the base::LINKER_INITIALIZED argument.  Normally, it is unsafe to declare a
+// the tcmalloc::LINKER_INITIALIZED argument.  Normally, it is unsafe to declare a
 // static variable that has a constructor or a destructor because invocation
 // order is undefined.  However, IF the type can be initialized by filling with
 // zeroes (which the loader does for static variables), AND the destructor also
 // does nothing to the storage, then a constructor declared as
-//       explicit MyClass(base::LinkerInitialized x) {}
+//       explicit MyClass(tcmalloc::LinkerInitialized x) {}
 // and invoked as
-//       static MyClass my_variable_name(base::LINKER_INITIALIZED);
-namespace base {
+//       static MyClass my_variable_name(tcmalloc::LINKER_INITIALIZED);
+namespace tcmalloc {
 enum LinkerInitialized { LINKER_INITIALIZED };
 }
 
diff --git a/src/base/elf_mem_image.cc b/src/base/elf_mem_image.cc
index d2ca1a5..fdfab4c 100644
--- a/src/base/elf_mem_image.cc
+++ b/src/base/elf_mem_image.cc
@@ -54,7 +54,7 @@
 
 #define VERSYM_VERSION 0x7fff
 
-namespace base {
+namespace tcmalloc {
 
 namespace {
 template <int N> class ElfClass {
@@ -429,6 +429,6 @@ void ElfMemImage::SymbolIterator::Update(int increment) {
   info_.symbol  = symbol;
 }
 
-}  // namespace base
+}  // namespace tcmalloc
 
 #endif  // HAVE_ELF_MEM_IMAGE
diff --git a/src/base/elf_mem_image.h b/src/base/elf_mem_image.h
index 5fb00ff..4fef045 100644
--- a/src/base/elf_mem_image.h
+++ b/src/base/elf_mem_image.h
@@ -50,7 +50,7 @@
 #include <stdlib.h>
 #include <link.h>  // for ElfW
 
-namespace base {
+namespace tcmalloc {
 
 // An in-memory ELF image (may not exist on disk).
 class ElfMemImage {
@@ -128,7 +128,7 @@ class ElfMemImage {
   ElfW(Addr) link_base_;     // Link-time base (p_vaddr of first PT_LOAD).
 };
 
-}  // namespace base
+}  // namespace tcmalloc
 
 #endif  // __ELF__ and __GLIBC__ and !__native_client__
 
diff --git a/src/base/spinlock.cc b/src/base/spinlock.cc
index d1b130b..49c7374 100644
--- a/src/base/spinlock.cc
+++ b/src/base/spinlock.cc
@@ -45,8 +45,8 @@
 
 static int adaptive_spin_count = 0;
 
-const base::LinkerInitialized SpinLock::LINKER_INITIALIZED =
-    base::LINKER_INITIALIZED;
+const tcmalloc::LinkerInitialized SpinLock::LINKER_INITIALIZED =
+    tcmalloc::LINKER_INITIALIZED;
 
 namespace {
 struct SpinLock_InitHelper {
@@ -130,7 +130,7 @@ void SpinLock::SlowLock() {
     }
 
     // Wait for an OS specific delay.
-    base::internal::SpinLockDelay(&lockword_, lock_value,
+    tcmalloc::internal::SpinLockDelay(&lockword_, lock_value,
                                   ++lock_wait_call_count);
     // Spin again after returning from the wait routine to give this thread
     // some chance of obtaining the lock.
@@ -140,5 +140,5 @@ void SpinLock::SlowLock() {
 
 void SpinLock::SlowUnlock() {
   // wake waiter if necessary
-  base::internal::SpinLockWake(&lockword_, false);
+  tcmalloc::internal::SpinLockWake(&lockword_, false);
 }
diff --git a/src/base/spinlock.h b/src/base/spinlock.h
index b336c45..510c13e 100644
--- a/src/base/spinlock.h
+++ b/src/base/spinlock.h
@@ -54,14 +54,14 @@ class LOCKABLE SpinLock {
 
   // Special constructor for use with static SpinLock objects.  E.g.,
   //
-  //    static SpinLock lock(base::LINKER_INITIALIZED);
+  //    static SpinLock lock(tcmalloc::LINKER_INITIALIZED);
   //
   // When intialized using this constructor, we depend on the fact
   // that the linker has already initialized the memory appropriately.
   // A SpinLock constructed like this can be freely used from global
   // initializers without worrying about the order in which global
   // initializers run.
-  explicit SpinLock(base::LinkerInitialized /*x*/) {
+  explicit SpinLock(tcmalloc::LinkerInitialized /*x*/) {
     // Does nothing; lockword_ is already initialized
   }
 
@@ -98,7 +98,7 @@ class LOCKABLE SpinLock {
     return lockword_.load(std::memory_order_relaxed) != kSpinLockFree;
   }
 
-  static const base::LinkerInitialized LINKER_INITIALIZED;  // backwards compat
+  static const tcmalloc::LinkerInitialized LINKER_INITIALIZED;  // backwards compat
  private:
   enum { kSpinLockFree = 0 };
   enum { kSpinLockHeld = 1 };
diff --git a/src/base/spinlock_internal.cc b/src/base/spinlock_internal.cc
index 204b4ce..72dc5ad 100644
--- a/src/base/spinlock_internal.cc
+++ b/src/base/spinlock_internal.cc
@@ -30,7 +30,7 @@
  */
 
 // The OS-specific header included below must provide two calls:
-// base::internal::SpinLockDelay() and base::internal::SpinLockWake().
+// tcmalloc::internal::SpinLockDelay() and tcmalloc::internal::SpinLockWake().
 // See spinlock_internal.h for the spec of SpinLockWake().
 
 // void SpinLockDelay(std::atomic<int> *w, int32 value, int loop)
@@ -44,7 +44,7 @@
 #include "base/spinlock_internal.h"
 
 // forward declaration for use by spinlock_*-inl.h
-namespace base { namespace internal { static int SuggestedDelayNS(int loop); }}
+namespace tcmalloc { namespace internal { static int SuggestedDelayNS(int loop); }}
 
 #if defined(_WIN32)
 #include "base/spinlock_win32-inl.h"
@@ -54,7 +54,7 @@ namespace base { namespace internal { static int SuggestedDelayNS(int loop); }}
 #include "base/spinlock_posix-inl.h"
 #endif
 
-namespace base {
+namespace tcmalloc {
 namespace internal {
 
 // Return a suggested delay in nanoseconds for iteration number "loop"
@@ -80,4 +80,4 @@ static int SuggestedDelayNS(int loop) {
 }
 
 } // namespace internal
-} // namespace base
+} // namespace tcmalloc
diff --git a/src/base/spinlock_internal.h b/src/base/spinlock_internal.h
index 4d74784..64a4bc0 100644
--- a/src/base/spinlock_internal.h
+++ b/src/base/spinlock_internal.h
@@ -42,12 +42,12 @@
 
 #include "base/basictypes.h"
 
-namespace base {
+namespace tcmalloc {
 namespace internal {
 
 void SpinLockWake(std::atomic<int> *w, bool all);
 void SpinLockDelay(std::atomic<int> *w, int32 value, int loop);
 
 } // namespace internal
-} // namespace base
+} // namespace tcmalloc
 #endif
diff --git a/src/base/spinlock_linux-inl.h b/src/base/spinlock_linux-inl.h
index 3f449d4..f602f69 100644
--- a/src/base/spinlock_linux-inl.h
+++ b/src/base/spinlock_linux-inl.h
@@ -66,7 +66,7 @@ static struct InitModule {
 }  // anonymous namespace
 
 
-namespace base {
+namespace tcmalloc {
 namespace internal {
 
 void SpinLockDelay(std::atomic<int> *w, int32 value, int loop) {
@@ -75,7 +75,7 @@ void SpinLockDelay(std::atomic<int> *w, int32 value, int loop) {
     struct timespec tm;
     tm.tv_sec = 0;
     if (have_futex) {
-      tm.tv_nsec = base::internal::SuggestedDelayNS(loop);
+      tm.tv_nsec = tcmalloc::internal::SuggestedDelayNS(loop);
     } else {
       tm.tv_nsec = 2000001;   // above 2ms so linux 2.4 doesn't spin
     }
@@ -99,4 +99,4 @@ void SpinLockWake(std::atomic<int> *w, bool all) {
 }
 
 } // namespace internal
-} // namespace base
+} // namespace tcmalloc
diff --git a/src/base/spinlock_posix-inl.h b/src/base/spinlock_posix-inl.h
index 2402cb4..5899c80 100644
--- a/src/base/spinlock_posix-inl.h
+++ b/src/base/spinlock_posix-inl.h
@@ -39,7 +39,7 @@
 #endif
 #include <time.h>       /* For nanosleep() */
 
-namespace base {
+namespace tcmalloc {
 namespace internal {
 
 void SpinLockDelay(std::atomic<int> *w, int32 value, int loop) {
@@ -50,7 +50,7 @@ void SpinLockDelay(std::atomic<int> *w, int32 value, int loop) {
   } else {
     struct timespec tm;
     tm.tv_sec = 0;
-    tm.tv_nsec = base::internal::SuggestedDelayNS(loop);
+    tm.tv_nsec = tcmalloc::internal::SuggestedDelayNS(loop);
     nanosleep(&tm, NULL);
   }
   errno = save_errno;
@@ -60,4 +60,4 @@ void SpinLockWake(std::atomic<int>  *w, bool all) {
 }
 
 } // namespace internal
-} // namespace base
+} // namespace tcmalloc
diff --git a/src/base/spinlock_win32-inl.h b/src/base/spinlock_win32-inl.h
index d511999..c0791a4 100644
--- a/src/base/spinlock_win32-inl.h
+++ b/src/base/spinlock_win32-inl.h
@@ -35,7 +35,7 @@
 
 #include <windows.h>
 
-namespace base {
+namespace tcmalloc {
 namespace internal {
 
 void SpinLockDelay(std::atomic<int> *w, int32 value, int loop) {
@@ -43,7 +43,7 @@ void SpinLockDelay(std::atomic<int> *w, int32 value, int loop) {
   } else if (loop == 1) {
     Sleep(0);
   } else {
-    Sleep(base::internal::SuggestedDelayNS(loop) / 1000000);
+    Sleep(tcmalloc::internal::SuggestedDelayNS(loop) / 1000000);
   }
 }
 
@@ -51,4 +51,4 @@ void SpinLockWake(std::atomic<int> *w, bool all) {
 }
 
 } // namespace internal
-} // namespace base
+} // namespace tcmalloc
diff --git a/src/base/vdso_support.cc b/src/base/vdso_support.cc
index 1e3c5b3..49da304 100644
--- a/src/base/vdso_support.cc
+++ b/src/base/vdso_support.cc
@@ -51,7 +51,7 @@
 #define AT_SYSINFO_EHDR 33
 #endif
 
-namespace base {
+namespace tcmalloc {
 
 const void *VDSOSupport::vdso_base_ = ElfMemImage::kInvalidBase;
 VDSOSupport::VDSOSupport()
diff --git a/src/base/vdso_support.h b/src/base/vdso_support.h
index 073386c..d85b764 100644
--- a/src/base/vdso_support.h
+++ b/src/base/vdso_support.h
@@ -70,7 +70,7 @@
 
 #include <stdlib.h>     // for NULL
 
-namespace base {
+namespace tcmalloc {
 
 // NOTE: this class may be used from within tcmalloc, and can not
 // use any memory allocation routines.
@@ -130,7 +130,7 @@ class VDSOSupport {
   DISALLOW_COPY_AND_ASSIGN(VDSOSupport);
 };
 
-}  // namespace base
+}  // namespace tcmalloc
 
 #endif  // HAVE_ELF_MEM_IMAGE
 
diff --git a/src/central_freelist.h b/src/central_freelist.h
index ceba600..03cf7f4 100644
--- a/src/central_freelist.h
+++ b/src/central_freelist.h
@@ -50,7 +50,7 @@ class CentralFreeList {
   // A CentralFreeList may be used before its constructor runs.
   // So we prevent lock_'s constructor from doing anything to the
   // lock_ state.
-  CentralFreeList() : lock_(base::LINKER_INITIALIZED) { }
+  CentralFreeList() : lock_(tcmalloc::LINKER_INITIALIZED) { }
 
   void Init(size_t cl);
 
diff --git a/src/emergency_malloc.cc b/src/emergency_malloc.cc
index 6c0946a..9b41253 100644
--- a/src/emergency_malloc.cc
+++ b/src/emergency_malloc.cc
@@ -47,7 +47,7 @@ namespace tcmalloc {
   __attribute__ ((visibility("internal"))) char *emergency_arena_start;
   __attribute__ ((visibility("internal"))) uintptr_t emergency_arena_start_shifted;
 
-  static CACHELINE_ALIGNED SpinLock emergency_malloc_lock(base::LINKER_INITIALIZED);
+  static CACHELINE_ALIGNED SpinLock emergency_malloc_lock(tcmalloc::LINKER_INITIALIZED);
   static char *emergency_arena_end;
   static LowLevelAlloc::Arena *emergency_arena;
 
diff --git a/src/gperftools/malloc_extension.h b/src/gperftools/malloc_extension.h
index 271ef5d..20db658 100644
--- a/src/gperftools/malloc_extension.h
+++ b/src/gperftools/malloc_extension.h
@@ -67,7 +67,7 @@ static const int kMallocHistogramSize = 64;
 // One day, we could support other types of writers (perhaps for C?)
 typedef std::string MallocExtensionWriter;
 
-namespace base {
+namespace tcmalloc {
 struct MallocRange;
 }
 
@@ -148,7 +148,7 @@ class PERFTOOLS_DLL_DECL MallocExtension {
   //
   // This is a best-effort interface useful only for performance
   // analysis.  The implementation may not call func at all.
-  typedef void (RangeFunction)(void*, const base::MallocRange*);
+  typedef void (RangeFunction)(void*, const tcmalloc::MallocRange*);
   virtual void Ranges(void* arg, RangeFunction func);
 
   // -------------------------------------------------------------------
@@ -416,7 +416,7 @@ class PERFTOOLS_DLL_DECL MallocExtension {
   virtual void MarkThreadTemporarilyIdle();
 };
 
-namespace base {
+namespace tcmalloc {
 
 // Information passed per range.  More fields may be added later.
 struct MallocRange {
@@ -439,6 +439,6 @@ struct MallocRange {
   // - age when allocated (for inuse) or freed (if not in use)
 };
 
-} // namespace base
+} // namespace tcmalloc
 
 #endif  // BASE_MALLOC_EXTENSION_H_
diff --git a/src/heap-profile-table.cc b/src/heap-profile-table.cc
index 455152e..c5dcd6e 100644
--- a/src/heap-profile-table.cc
+++ b/src/heap-profile-table.cc
@@ -590,7 +590,7 @@ void HeapProfileTable::Snapshot::ReportLeaks(const char* checker_name,
     symbolization_table.Symbolize();
   for (int i = 0; i < to_report; i++) {
     const Entry& e = entries[i];
-    base::RawPrinter printer(buffer, kBufSize);
+    tcmalloc::RawPrinter printer(buffer, kBufSize);
     printer.Printf("Leak of %zu bytes in %d objects allocated from:\n",
                    e.bytes, e.count);
     for (int j = 0; j < e.bucket->depth; j++) {
diff --git a/src/internal_logging.cc b/src/internal_logging.cc
index ca1c86e..62db989 100644
--- a/src/internal_logging.cc
+++ b/src/internal_logging.cc
@@ -47,7 +47,7 @@
 
 // Variables for storing crash output.  Allocated statically since we
 // may not be able to heap-allocate while crashing.
-static SpinLock crash_lock(base::LINKER_INITIALIZED);
+static SpinLock crash_lock(tcmalloc::LINKER_INITIALIZED);
 static bool crashed = false;
 static const int kStatsBufferSize = 16 << 10;
 static char stats_buffer[kStatsBufferSize] = { 0 };
diff --git a/src/malloc_hook-inl.h b/src/malloc_hook-inl.h
index ddf6a5a..33997af 100644
--- a/src/malloc_hook-inl.h
+++ b/src/malloc_hook-inl.h
@@ -48,7 +48,7 @@
 
 #include "common.h" // for UNLIKELY
 
-namespace base { namespace internal {
+namespace tcmalloc { namespace internal {
 
 // Capacity of 8 means that HookList is 9 words.
 static const int kHookListCapacity = 8;
@@ -121,26 +121,26 @@ struct PERFTOOLS_DLL_DECL HookList {
 ATTRIBUTE_VISIBILITY_HIDDEN extern HookList<MallocHook::NewHook> new_hooks_;
 ATTRIBUTE_VISIBILITY_HIDDEN extern HookList<MallocHook::DeleteHook> delete_hooks_;
 
-} }  // namespace base::internal
+} }  // namespace tcmalloc::internal
 
 // The following method is DEPRECATED
 inline MallocHook::NewHook MallocHook::GetNewHook() {
-  return base::internal::new_hooks_.GetSingular();
+  return tcmalloc::internal::new_hooks_.GetSingular();
 }
 
 inline void MallocHook::InvokeNewHook(const void* p, size_t s) {
-  if (PREDICT_FALSE(!base::internal::new_hooks_.empty())) {
+  if (PREDICT_FALSE(!tcmalloc::internal::new_hooks_.empty())) {
     InvokeNewHookSlow(p, s);
   }
 }
 
 // The following method is DEPRECATED
 inline MallocHook::DeleteHook MallocHook::GetDeleteHook() {
-  return base::internal::delete_hooks_.GetSingular();
+  return tcmalloc::internal::delete_hooks_.GetSingular();
 }
 
 inline void MallocHook::InvokeDeleteHook(const void* p) {
-  if (PREDICT_FALSE(!base::internal::delete_hooks_.empty())) {
+  if (PREDICT_FALSE(!tcmalloc::internal::delete_hooks_.empty())) {
     InvokeDeleteHookSlow(p);
   }
 }
diff --git a/src/malloc_hook.cc b/src/malloc_hook.cc
index 79917b6..ae8fc62 100644
--- a/src/malloc_hook.cc
+++ b/src/malloc_hook.cc
@@ -142,13 +142,13 @@ bool RemoveInitialHooksAndCallInitializers() {
 
 }  // namespace
 
-namespace base { namespace internal {
+namespace tcmalloc { namespace internal {
 
 // This lock is shared between all implementations of HookList::Add & Remove.
 // The potential for contention is very small.  This needs to be a SpinLock and
 // not a Mutex since it's possible for Mutex locking to allocate memory (e.g.,
 // per-thread allocation in debug builds), which could cause infinite recursion.
-static SpinLock hooklist_spinlock(base::LINKER_INITIALIZED);
+static SpinLock hooklist_spinlock(tcmalloc::LINKER_INITIALIZED);
 
 template <typename T>
 bool HookList<T>::Add(T value) {
@@ -239,11 +239,11 @@ template struct HookList<MallocHook::NewHook>;
 HookList<MallocHook::NewHook> new_hooks_{InitialNewHook};
 HookList<MallocHook::DeleteHook> delete_hooks_;
 
-} }  // namespace base::internal
+} }  // namespace tcmalloc::internal
 
-using base::internal::kHookListMaxValues;
-using base::internal::new_hooks_;
-using base::internal::delete_hooks_;
+using tcmalloc::internal::kHookListMaxValues;
+using tcmalloc::internal::new_hooks_;
+using tcmalloc::internal::delete_hooks_;
 
 // These are available as C bindings as well as C++, hence their
 // definition outside the MallocHook class.
diff --git a/src/mmap_hook.cc b/src/mmap_hook.cc
index 0b9aa08..9fa9bab 100644
--- a/src/mmap_hook.cc
+++ b/src/mmap_hook.cc
@@ -83,7 +83,7 @@ static_assert(alignof(MappingHookDescriptor) == alignof(MappingHookSpace), "");
 
 class MappingHooks {
 public:
-  MappingHooks(base::LinkerInitialized) {}
+  MappingHooks(tcmalloc::LinkerInitialized) {}
 
   static MappingHookDescriptor* SpaceToDesc(MappingHookSpace* space) {
     return reinterpret_cast<MappingHookDescriptor*>(space->storage);
@@ -148,7 +148,7 @@ public:
 private:
   std::atomic<MappingHookDescriptor*> list_head_;
   std::atomic<bool> ran_initial_hooks_;
-} mapping_hooks{base::LINKER_INITIALIZED};
+} mapping_hooks{tcmalloc::LINKER_INITIALIZED};
 
 }  // namespace
 
diff --git a/src/page_heap.cc b/src/page_heap.cc
index 386a0ec..6e4aed4 100644
--- a/src/page_heap.cc
+++ b/src/page_heap.cc
@@ -691,7 +691,7 @@ void PageHeap::GetLargeSpanStatsLocked(LargeSpanStats* result) {
   }
 }
 
-bool PageHeap::GetNextRange(PageID start, base::MallocRange* r) {
+bool PageHeap::GetNextRange(PageID start, tcmalloc::MallocRange* r) {
   ASSERT(lock_.IsHeld());
   Span* span = reinterpret_cast<Span*>(pagemap_.Next(start));
   if (span == NULL) {
@@ -702,7 +702,7 @@ bool PageHeap::GetNextRange(PageID start, base::MallocRange* r) {
   r->fraction = 0;
   switch (span->location) {
     case Span::IN_USE:
-      r->type = base::MallocRange::INUSE;
+      r->type = tcmalloc::MallocRange::INUSE;
       r->fraction = 1;
       if (span->sizeclass > 0) {
         // Only some of the objects in this span may be in use.
@@ -711,13 +711,13 @@ bool PageHeap::GetNextRange(PageID start, base::MallocRange* r) {
       }
       break;
     case Span::ON_NORMAL_FREELIST:
-      r->type = base::MallocRange::FREE;
+      r->type = tcmalloc::MallocRange::FREE;
       break;
     case Span::ON_RETURNED_FREELIST:
-      r->type = base::MallocRange::UNMAPPED;
+      r->type = tcmalloc::MallocRange::UNMAPPED;
       break;
     default:
-      r->type = base::MallocRange::UNKNOWN;
+      r->type = tcmalloc::MallocRange::UNKNOWN;
       break;
   }
   return true;
diff --git a/src/page_heap.h b/src/page_heap.h
index 12b447f..9c135fd 100644
--- a/src/page_heap.h
+++ b/src/page_heap.h
@@ -65,7 +65,7 @@
 # include <gperftools/stacktrace.h>
 #endif
 
-namespace base {
+namespace tcmalloc {
 struct MallocRange;
 }
 
@@ -168,7 +168,7 @@ class PERFTOOLS_DLL_DECL PageHeap {
 
   // If this page heap is managing a range with starting page # >= start,
   // store info about the range in *r and return true.  Else return false.
-  bool GetNextRange(PageID start, base::MallocRange* r);
+  bool GetNextRange(PageID start, tcmalloc::MallocRange* r);
 
   // Page heap statistics
   struct Stats {
diff --git a/src/page_heap_allocator.h b/src/page_heap_allocator.h
index 3fecabd..9a2f791 100644
--- a/src/page_heap_allocator.h
+++ b/src/page_heap_allocator.h
@@ -164,7 +164,7 @@ class STLPageHeapAllocator {
 
  private:
   struct Storage {
-    explicit Storage(base::LinkerInitialized x) {}
+    explicit Storage(tcmalloc::LinkerInitialized x) {}
     PageHeapAllocator<T> allocator;
     bool initialized;
   };
@@ -172,7 +172,7 @@ class STLPageHeapAllocator {
 };
 
 template<typename T, class LockingTag>
-typename STLPageHeapAllocator<T, LockingTag>::Storage STLPageHeapAllocator<T, LockingTag>::underlying_(base::LINKER_INITIALIZED);
+typename STLPageHeapAllocator<T, LockingTag>::Storage STLPageHeapAllocator<T, LockingTag>::underlying_(tcmalloc::LINKER_INITIALIZED);
 
 }  // namespace tcmalloc
 
diff --git a/src/raw_printer.cc b/src/raw_printer.cc
index 785d473..7b38b88 100644
--- a/src/raw_printer.cc
+++ b/src/raw_printer.cc
@@ -37,7 +37,7 @@
 #include "raw_printer.h"
 #include "base/logging.h"
 
-namespace base {
+namespace tcmalloc {
 
 RawPrinter::RawPrinter(char* buf, int length)
     : base_(buf),
diff --git a/src/raw_printer.h b/src/raw_printer.h
index 5f57bbf..860dca9 100644
--- a/src/raw_printer.h
+++ b/src/raw_printer.h
@@ -46,7 +46,7 @@
 #include <config.h>
 #include "base/basictypes.h"
 
-namespace base {
+namespace tcmalloc {
 
 class RawPrinter {
  public:
diff --git a/src/stacktrace_powerpc-linux-inl.h b/src/stacktrace_powerpc-linux-inl.h
index 883e7d2..139f8dd 100644
--- a/src/stacktrace_powerpc-linux-inl.h
+++ b/src/stacktrace_powerpc-linux-inl.h
@@ -149,8 +149,8 @@ static int GET_STACK_TRACE_OR_FRAMES {
   skip_count++; // skip parent's frame due to indirection in
                 // stacktrace.cc
 
-  base::VDSOSupport vdso;
-  base::ElfMemImage::SymbolInfo rt_sigreturn_symbol_info;
+  tcmalloc::VDSOSupport vdso;
+  tcmalloc::ElfMemImage::SymbolInfo rt_sigreturn_symbol_info;
 #ifdef __PPC64__
   const void *sigtramp64_vdso = 0;
   if (vdso.LookupSymbol("__kernel_sigtramp_rt64", "LINUX_2.6.15", STT_NOTYPE,
diff --git a/src/tcmalloc.cc b/src/tcmalloc.cc
index 47c6a61..d863c14 100644
--- a/src/tcmalloc.cc
+++ b/src/tcmalloc.cc
@@ -566,7 +566,7 @@ static void IterateOverRanges(void* arg, MallocExtension::RangeFunction func) {
   while (!done) {
     // Accumulate a small number of ranges in a local buffer
     static const int kNumRanges = 16;
-    static base::MallocRange ranges[kNumRanges];
+    static tcmalloc::MallocRange ranges[kNumRanges];
     int n = 0;
     {
       SpinLockHolder h(Static::pageheap_lock());
@@ -1877,7 +1877,7 @@ void* memalign_pages(size_t align, size_t size,
 template <void* OOMHandler(size_t)>
 ATTRIBUTE_ALWAYS_INLINE inline
 static void * malloc_fast_path(size_t size) {
-  if (PREDICT_FALSE(!base::internal::new_hooks_.empty())) {
+  if (PREDICT_FALSE(!tcmalloc::internal::new_hooks_.empty())) {
     return tcmalloc::dispatch_allocate_full<OOMHandler>(size);
   }
 
@@ -1928,7 +1928,7 @@ void* tc_malloc(size_t size) PERFTOOLS_NOTHROW {
 
 static ATTRIBUTE_ALWAYS_INLINE inline
 void free_fast_path(void *ptr) {
-  if (PREDICT_FALSE(!base::internal::delete_hooks_.empty())) {
+  if (PREDICT_FALSE(!tcmalloc::internal::delete_hooks_.empty())) {
     tcmalloc::invoke_hooks_and_free(ptr);
     return;
   }
@@ -1942,7 +1942,7 @@ void tc_free(void* ptr) PERFTOOLS_NOTHROW {
 
 extern "C" PERFTOOLS_DLL_DECL CACHELINE_ALIGNED_FN
 void tc_free_sized(void *ptr, size_t size) PERFTOOLS_NOTHROW {
-  if (PREDICT_FALSE(!base::internal::delete_hooks_.empty())) {
+  if (PREDICT_FALSE(!tcmalloc::internal::delete_hooks_.empty())) {
     tcmalloc::invoke_hooks_and_free(ptr);
     return;
   }
@@ -2041,7 +2041,7 @@ TC_ALIAS(tc_free);
 // But it's really the same as normal delete, so we just do the same thing.
 extern "C" PERFTOOLS_DLL_DECL void tc_delete_nothrow(void* p, const std::nothrow_t&) PERFTOOLS_NOTHROW
 {
-  if (PREDICT_FALSE(!base::internal::delete_hooks_.empty())) {
+  if (PREDICT_FALSE(!tcmalloc::internal::delete_hooks_.empty())) {
     tcmalloc::invoke_hooks_and_free(p);
     return;
   }
diff --git a/src/tests/heap-checker_unittest.cc b/src/tests/heap-checker_unittest.cc
index 9a7086c..f93d6ea 100644
--- a/src/tests/heap-checker_unittest.cc
+++ b/src/tests/heap-checker_unittest.cc
@@ -801,7 +801,7 @@ static void DirectTestSTLAlloc(Alloc allocator, const char* name) {
   CHECK(check.BriefSameHeap());  // just in case
 }
 
-static SpinLock grplock{base::LINKER_INITIALIZED};
+static SpinLock grplock{tcmalloc::LINKER_INITIALIZED};
 static struct group* grp = NULL;
 static const int kKeys = 50;
 static pthread_key_t key[kKeys];
diff --git a/src/tests/malloc_hook_test.cc b/src/tests/malloc_hook_test.cc
index a128355..af9b842 100644
--- a/src/tests/malloc_hook_test.cc
+++ b/src/tests/malloc_hook_test.cc
@@ -87,12 +87,12 @@ void Sleep(int seconds) {
 #endif
 }
 
-using base::internal::kHookListMaxValues;
+using tcmalloc::internal::kHookListMaxValues;
 
 // Since HookList is a template and is defined in malloc_hook.cc, we can only
 // use an instantiation of it from malloc_hook.cc.  We then reinterpret those
 // values as integers for testing.
-typedef base::internal::HookList<MallocHook::NewHook> TestHookList;
+typedef tcmalloc::internal::HookList<MallocHook::NewHook> TestHookList;
 
 
 const MallocHook::NewHook kTestValue = reinterpret_cast<MallocHook::NewHook>(69);
diff --git a/src/tests/raw_printer_test.cc b/src/tests/raw_printer_test.cc
index 2c7be6a..99a2f13 100644
--- a/src/tests/raw_printer_test.cc
+++ b/src/tests/raw_printer_test.cc
@@ -17,7 +17,7 @@ using std::string;
 
 TEST(RawPrinter, Empty) {
   char buffer[1];
-  base::RawPrinter printer(buffer, arraysize(buffer));
+  tcmalloc::RawPrinter printer(buffer, arraysize(buffer));
   CHECK_EQ(0, printer.length());
   CHECK_EQ(string(""), buffer);
   CHECK_EQ(0, printer.space_left());
@@ -29,7 +29,7 @@ TEST(RawPrinter, Empty) {
 
 TEST(RawPrinter, PartiallyFilled) {
   char buffer[100];
-  base::RawPrinter printer(buffer, arraysize(buffer));
+  tcmalloc::RawPrinter printer(buffer, arraysize(buffer));
   printer.Printf("%s %s", "hello", "world");
   CHECK_EQ(string("hello world"), string(buffer));
   CHECK_EQ(11, printer.length());
@@ -38,7 +38,7 @@ TEST(RawPrinter, PartiallyFilled) {
 
 TEST(RawPrinter, Truncated) {
   char buffer[3];
-  base::RawPrinter printer(buffer, arraysize(buffer));
+  tcmalloc::RawPrinter printer(buffer, arraysize(buffer));
   printer.Printf("%d", 12345678);
   CHECK_EQ(string("12"), string(buffer));
   CHECK_EQ(2, printer.length());
@@ -47,7 +47,7 @@ TEST(RawPrinter, Truncated) {
 
 TEST(RawPrinter, ExactlyFilled) {
   char buffer[12];
-  base::RawPrinter printer(buffer, arraysize(buffer));
+  tcmalloc::RawPrinter printer(buffer, arraysize(buffer));
   printer.Printf("%s %s", "hello", "world");
   CHECK_EQ(string("hello world"), string(buffer));
   CHECK_EQ(11, printer.length());
diff --git a/src/tests/tcmalloc_unittest.cc b/src/tests/tcmalloc_unittest.cc
index 707840a..a199901 100644
--- a/src/tests/tcmalloc_unittest.cc
+++ b/src/tests/tcmalloc_unittest.cc
@@ -829,21 +829,21 @@ namespace {
 
 struct RangeCallbackState {
   uintptr_t ptr;
-  base::MallocRange::Type expected_type;
+  tcmalloc::MallocRange::Type expected_type;
   size_t min_size;
   bool matched;
 };
 
-static void RangeCallback(void* arg, const base::MallocRange* r) {
+static void RangeCallback(void* arg, const tcmalloc::MallocRange* r) {
   RangeCallbackState* state = reinterpret_cast<RangeCallbackState*>(arg);
   if (state->ptr >= r->address &&
       state->ptr < r->address + r->length) {
-    if (state->expected_type == base::MallocRange::FREE) {
+    if (state->expected_type == tcmalloc::MallocRange::FREE) {
       // We are expecting r->type == FREE, but ReleaseMemory
       // may have already moved us to UNMAPPED state instead (this happens in
       // approximately 0.1% of executions). Accept either state.
-      CHECK(r->type == base::MallocRange::FREE ||
-            r->type == base::MallocRange::UNMAPPED);
+      CHECK(r->type == tcmalloc::MallocRange::FREE ||
+            r->type == tcmalloc::MallocRange::UNMAPPED);
     } else {
       CHECK_EQ(r->type, state->expected_type);
     }
@@ -855,7 +855,7 @@ static void RangeCallback(void* arg, const base::MallocRange* r) {
 // Check that at least one of the callbacks from Ranges() contains
 // the specified address with the specified type, and has size
 // >= min_size.
-static void CheckRangeCallback(void* ptr, base::MallocRange::Type type,
+static void CheckRangeCallback(void* ptr, tcmalloc::MallocRange::Type type,
                                size_t min_size) {
   RangeCallbackState state;
   state.ptr = reinterpret_cast<uintptr_t>(ptr);
@@ -881,20 +881,20 @@ static void TestRanges() {
   static const int MB = 1048576;
   void* a = malloc(MB);
   void* b = malloc(MB);
-  base::MallocRange::Type releasedType =
-    HaveSystemRelease() ? base::MallocRange::UNMAPPED : base::MallocRange::FREE;
+  tcmalloc::MallocRange::Type releasedType =
+    HaveSystemRelease() ? tcmalloc::MallocRange::UNMAPPED : tcmalloc::MallocRange::FREE;
 
-  CheckRangeCallback(a, base::MallocRange::INUSE, MB);
-  CheckRangeCallback(b, base::MallocRange::INUSE, MB);
+  CheckRangeCallback(a, tcmalloc::MallocRange::INUSE, MB);
+  CheckRangeCallback(b, tcmalloc::MallocRange::INUSE, MB);
   (noopt(free))(a);
-  CheckRangeCallback(a, base::MallocRange::FREE, MB);
-  CheckRangeCallback(b, base::MallocRange::INUSE, MB);
+  CheckRangeCallback(a, tcmalloc::MallocRange::FREE, MB);
+  CheckRangeCallback(b, tcmalloc::MallocRange::INUSE, MB);
   MallocExtension::instance()->ReleaseFreeMemory();
   CheckRangeCallback(a, releasedType, MB);
-  CheckRangeCallback(b, base::MallocRange::INUSE, MB);
+  CheckRangeCallback(b, tcmalloc::MallocRange::INUSE, MB);
   (noopt(free))(b);
   CheckRangeCallback(a, releasedType, MB);
-  CheckRangeCallback(b, base::MallocRange::FREE, MB);
+  CheckRangeCallback(b, tcmalloc::MallocRange::FREE, MB);
 }
 
 #ifndef DEBUGALLOCATION
