# --kudu_master_hosts=kudu-master-1:7051,kudu-master-2:7151,kudu-master-3:7251

# val df = spark.read
#   .options(Map("kudu.master" -> "kudu-master-1:7051,kudu-master-2:7151,kudu-master-3:7251", "kudu.table" -> "kudu_table"))
#   .format("kudu").load

#   val kuduContext = new KuduContext("kudu-master-1:7051,kudu-master-2:7151,kudu-master-3:7251", spark.sparkContext)
# kuduContext.createTable("test_table", schema, Seq("Name"),new CreateTableOptions().setNumReplicas(1).addHashPartitions(List("Name").asJava, 3))

#         import org.apache.kudu.client._
# import collection.JavaConverters._

# // Read a table from Kudu
# val df = spark.read
#   .options(Map("kudu.master" -> "kudu-master:7051", "kudu.table" -> "test_table"))
#   .format("kudu").load()

#   spark-shell --packages org.apache.kudu:kudu-spark3_2.12:1.17.0

# val schema = StructType(
#   Seq(
#     StructField("Name", StringType, nullable = false),
#     StructField("Age", IntegerType, nullable = true),
#     StructField("City", StringType, nullable = true)
#   )
# )

# val df = spark.read
#   .options(Map("kudu.master" -> "kudu-master-1:7051,kudu-master-2:7151,kudu-master-3:7251", "kudu.table" -> "test_table"))
#   .format("kudu").load()

# docker run -d --name kudu-impala  -p 21000:21000 -p 21050:21050 -p 25000:25000 -p 25010:25010 -p 25020:25020 --memory=4096m --network=docker_localnet apache/kudu:impala-latest impala
# docker exec -it kudu-impala impala-shell
CREATE EXTERNAL TABLE line_item
STORED AS KUDU
TBLPROPERTIES (
  'kudu.table_name' = 'line_item',
  'kudu.master_addresses' = 'kudu-master-1:7051,kudu-master-2:7151,kudu-master-3:7251'
);

impala-shell -q "query string" 2>&1 | grep -Po "\d+\.\d+(?=s)"

docker stop kudu-impala
docker remove kudu-impala

